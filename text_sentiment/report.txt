1. Преимущества выбранной библиотеки (Hugging Face Transformers)

Библиотека Hugging Face Transformers была выбрана для решения задачи анализа тональности текста по следующим причинам:

Готовые предобученные модели: позволяет использовать мощные модели, такие как distilbert-base-uncased-finetuned-sst-2-english, без необходимости обучения с нуля.

Высокая точность: модели Hugging Face демонстрируют конкурентные результаты на задачах обработки естественного языка (NLP).

2. Принцип работы модели и причины её выбора

Используемая модель distilbert-base-uncased-finetuned-sst-2-english — это облегчённая версия BERT, обученная на датасете SST-2 (Stanford Sentiment Treebank).

Принцип работы модели:

Токенизация: текст преобразуется в числовое представление с учётом контекста.

Векторизация: токенизированные данные проходят через слои нейронной сети, где учитываются взаимосвязи между словами.

Классификация: финальный слой выдаёт вероятности классов (positive / negative).

Интерпретация: выбирается класс с наибольшей вероятностью, а также сохраняется уровень уверенности модели.

Причины выбора модели:

Она компактна (меньше параметров, чем у BERT), но при этом даёт высокую точность.

Поддерживается в Hugging Face, что упрощает интеграцию и обновление.

Хорошо подходит для анализа коротких пользовательских отзывов.

3. Структура датасета

Входные данные представлены в виде текстовых файлов (input.txt) и CSV-таблицы (input.csv).

Пример структуры данных:

TXT
I absolutely love this product! It works perfectly.
This is the worst thing I’ve ever bought.

4. Для оценки качества модели использовались метрики accuracy(доля правильно предсказанных классов) и precision(насколько точно

модель предсказывает позитивные тесты)

5. Особенности реализации алгоритма и его эффективность

Особенности реализации:

Используется pipeline от Hugging Face, что делает код лаконичным.

Обрабатываются как TXT, так и CSV файлы.

Добавлена поддержка вероятностной оценки (score).

Используется pandas для удобного сохранения результатов в CSV.